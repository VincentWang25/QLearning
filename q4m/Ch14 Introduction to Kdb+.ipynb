{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Tables-in-Memory-and-Serialization\" data-toc-modified-id=\"Tables-in-Memory-and-Serialization-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Tables in Memory and Serialization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tables-and-Keyed-Tables\" data-toc-modified-id=\"Tables-and-Keyed-Tables-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Tables and Keyed Tables</a></span></li><li><span><a href=\"#Foreign-Keys-and-Link-Columns\" data-toc-modified-id=\"Foreign-Keys-and-Link-Columns-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Foreign Keys and Link Columns</a></span></li><li><span><a href=\"#Serializing-Tables\" data-toc-modified-id=\"Serializing-Tables-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Serializing Tables</a></span></li><li><span><a href=\"#Operating-on-Serialized-Tables\" data-toc-modified-id=\"Operating-on-Serialized-Tables-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Operating on Serialized Tables</a></span></li><li><span><a href=\"#The-Database-View\" data-toc-modified-id=\"The-Database-View-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>The Database View</a></span></li></ul></li><li><span><a href=\"#Splayed-Tables\" data-toc-modified-id=\"Splayed-Tables-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Splayed Tables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-Splayed-Tables\" data-toc-modified-id=\"Creating-Splayed-Tables-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Creating Splayed Tables</a></span></li><li><span><a href=\"#Splayed-Tables-with-Symbol-Columns\" data-toc-modified-id=\"Splayed-Tables-with-Symbol-Columns-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Splayed Tables with Symbol Columns</a></span></li><li><span><a href=\"#Splayed-Tables-with-Nested-Columns\" data-toc-modified-id=\"Splayed-Tables-with-Nested-Columns-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Splayed Tables with Nested Columns</a></span></li><li><span><a href=\"#Basic-Operations-on-Splayed-Tables\" data-toc-modified-id=\"Basic-Operations-on-Splayed-Tables-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Basic Operations on Splayed Tables</a></span></li><li><span><a href=\"#Operations-on-a-Splayed-Directory\" data-toc-modified-id=\"Operations-on-a-Splayed-Directory-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Operations on a Splayed Directory</a></span></li><li><span><a href=\"#Appending-to-a-Splayed-Table\" data-toc-modified-id=\"Appending-to-a-Splayed-Table-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Appending to a Splayed Table</a></span></li><li><span><a href=\"#Mannual-Operations-On-a-Splayed-Directory\" data-toc-modified-id=\"Mannual-Operations-On-a-Splayed-Directory-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Mannual Operations On a Splayed Directory</a></span></li><li><span><a href=\"#Working-with-sym-Files\" data-toc-modified-id=\"Working-with-sym-Files-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>Working with sym Files</a></span></li><li><span><a href=\"#Splayed-Tables-with-Link-Columns\" data-toc-modified-id=\"Splayed-Tables-with-Link-Columns-2.9\"><span class=\"toc-item-num\">2.9&nbsp;&nbsp;</span>Splayed Tables with Link Columns</a></span></li><li><span><a href=\"#Query-Execution-on-Splayed-Tables\" data-toc-modified-id=\"Query-Execution-on-Splayed-Tables-2.10\"><span class=\"toc-item-num\">2.10&nbsp;&nbsp;</span>Query Execution on Splayed Tables</a></span></li></ul></li><li><span><a href=\"#Partitioned-Tables\" data-toc-modified-id=\"Partitioned-Tables-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Partitioned Tables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Partitions\" data-toc-modified-id=\"Partitions-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Partitions</a></span></li><li><span><a href=\"#Partition-Domain\" data-toc-modified-id=\"Partition-Domain-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Partition Domain</a></span></li><li><span><a href=\"#Creating-Partitioned-Tables\" data-toc-modified-id=\"Creating-Partitioned-Tables-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Creating Partitioned Tables</a></span></li><li><span><a href=\"#Working-with-Partitioned-Tables\" data-toc-modified-id=\"Working-with-Partitioned-Tables-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Working with Partitioned Tables</a></span></li><li><span><a href=\"#The-Virtual-Column-i-in-Partitioned-Tables\" data-toc-modified-id=\"The-Virtual-Column-i-in-Partitioned-Tables-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>The Virtual Column <code>i</code> in Partitioned Tables</a></span></li><li><span><a href=\"#Query-Execution-on-Partitioned-Tables\" data-toc-modified-id=\"Query-Execution-on-Partitioned-Tables-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Query Execution on Partitioned Tables</a></span></li><li><span><a href=\"#Map-Reduce\" data-toc-modified-id=\"Map-Reduce-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Map-Reduce</a></span></li><li><span><a href=\"#Multiple-Partitioned-Tables\" data-toc-modified-id=\"Multiple-Partitioned-Tables-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>Multiple Partitioned Tables</a></span></li><li><span><a href=\"#Examples-of-Other-Partition-Domain-Types\" data-toc-modified-id=\"Examples-of-Other-Partition-Domain-Types-3.9\"><span class=\"toc-item-num\">3.9&nbsp;&nbsp;</span>Examples of Other Partition Domain Types</a></span></li><li><span><a href=\"#Partitioned-Tables-with-Links\" data-toc-modified-id=\"Partitioned-Tables-with-Links-3.10\"><span class=\"toc-item-num\">3.10&nbsp;&nbsp;</span>Partitioned Tables with Links</a></span></li></ul></li><li><span><a href=\"#Segmented-Tables\" data-toc-modified-id=\"Segmented-Tables-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Segmented Tables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Segments\" data-toc-modified-id=\"Segments-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Segments</a></span></li><li><span><a href=\"#Segmentation-vs.-Partitions\" data-toc-modified-id=\"Segmentation-vs.-Partitions-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Segmentation vs. Partitions</a></span></li><li><span><a href=\"#Creating-Segmented-Tables\" data-toc-modified-id=\"Creating-Segmented-Tables-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Creating Segmented Tables</a></span></li><li><span><a href=\"#Multiple-Segmented-Tables\" data-toc-modified-id=\"Multiple-Segmented-Tables-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Multiple Segmented Tables</a></span></li><li><span><a href=\"#Query-Execution-against-Segmented-Tables\" data-toc-modified-id=\"Query-Execution-against-Segmented-Tables-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Query Execution against Segmented Tables</a></span></li><li><span><a href=\"#Balancing-Slaves-and-Cores\" data-toc-modified-id=\"Balancing-Slaves-and-Cores-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Balancing Slaves and Cores</a></span></li><li><span><a href=\"#Sample-Performance-Data\" data-toc-modified-id=\"Sample-Performance-Data-4.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>Sample Performance Data</a></span></li></ul></li><li><span><a href=\"#Utilities-for-Splaying-and-Partitioning\" data-toc-modified-id=\"Utilities-for-Splaying-and-Partitioning-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Utilities for Splaying and Partitioning</a></span><ul class=\"toc-item\"><li><span><a href=\"#.Q.qp\" data-toc-modified-id=\".Q.qp-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span><code>.Q.qp</code></a></span></li><li><span><a href=\"#.Q.en\" data-toc-modified-id=\".Q.en-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span><code>.Q.en</code></a></span></li><li><span><a href=\"#.Q.pv\" data-toc-modified-id=\".Q.pv-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span><code>.Q.pv</code></a></span></li><li><span><a href=\"#.Q.ind\" data-toc-modified-id=\".Q.ind-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span><code>.Q.ind</code></a></span></li><li><span><a href=\"#.Q.dpft\" data-toc-modified-id=\".Q.dpft-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span><code>.Q.dpft</code></a></span></li><li><span><a href=\"#.Q.fs\" data-toc-modified-id=\".Q.fs-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span><code>.Q.fs</code></a></span></li><li><span><a href=\"#.Q.chk\" data-toc-modified-id=\".Q.chk-5.7\"><span class=\"toc-item-num\">5.7&nbsp;&nbsp;</span><code>.Q.chk</code></a></span></li><li><span><a href=\"#.Q.view\" data-toc-modified-id=\".Q.view-5.8\"><span class=\"toc-item-num\">5.8&nbsp;&nbsp;</span><code>.Q.view</code></a></span></li></ul></li><li><span><a href=\"#Kdb-Database\" data-toc-modified-id=\"Kdb-Database-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Kdb Database</a></span><ul class=\"toc-item\"><li><span><a href=\"#Comparing-kdb+-to-an-RDBMS\" data-toc-modified-id=\"Comparing-kdb+-to-an-RDBMS-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Comparing kdb+ to an RDBMS</a></span></li><li><span><a href=\"#The-Physical-Layout-of-a-kdb+-Database\" data-toc-modified-id=\"The-Physical-Layout-of-a-kdb+-Database-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>The Physical Layout of a kdb+ Database</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-sym-File\" data-toc-modified-id=\"The-sym-File-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>The <code>sym</code> File</a></span></li><li><span><a href=\"#Other-Serialized-Files-in-Root\" data-toc-modified-id=\"Other-Serialized-Files-in-Root-6.2.2\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>Other Serialized Files in Root</a></span></li><li><span><a href=\"#Scripts\" data-toc-modified-id=\"Scripts-6.2.3\"><span class=\"toc-item-num\">6.2.3&nbsp;&nbsp;</span>Scripts</a></span></li><li><span><a href=\"#Splayed-Tables\" data-toc-modified-id=\"Splayed-Tables-6.2.4\"><span class=\"toc-item-num\">6.2.4&nbsp;&nbsp;</span>Splayed Tables</a></span></li><li><span><a href=\"#Partitioned-Tables\" data-toc-modified-id=\"Partitioned-Tables-6.2.5\"><span class=\"toc-item-num\">6.2.5&nbsp;&nbsp;</span>Partitioned Tables</a></span></li><li><span><a href=\"#Segmented-Tables\" data-toc-modified-id=\"Segmented-Tables-6.2.6\"><span class=\"toc-item-num\">6.2.6&nbsp;&nbsp;</span>Segmented Tables</a></span></li></ul></li><li><span><a href=\"#Creating-and-Populating-a-kdb+-Database\" data-toc-modified-id=\"Creating-and-Populating-a-kdb+-Database-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Creating and Populating a kdb+ Database</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-happens-at-startup?\" data-toc-modified-id=\"What-happens-at-startup?-6.3.1\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;</span>What happens at startup?</a></span></li><li><span><a href=\"#Serialized-q-Entities\" data-toc-modified-id=\"Serialized-q-Entities-6.3.2\"><span class=\"toc-item-num\">6.3.2&nbsp;&nbsp;</span>Serialized q Entities</a></span></li><li><span><a href=\"#Splayed-Tables\" data-toc-modified-id=\"Splayed-Tables-6.3.3\"><span class=\"toc-item-num\">6.3.3&nbsp;&nbsp;</span>Splayed Tables</a></span></li><li><span><a href=\"#Partitioned-Tables\" data-toc-modified-id=\"Partitioned-Tables-6.3.4\"><span class=\"toc-item-num\">6.3.4&nbsp;&nbsp;</span>Partitioned Tables</a></span></li><li><span><a href=\"#Segmented-Tables\" data-toc-modified-id=\"Segmented-Tables-6.3.5\"><span class=\"toc-item-num\">6.3.5&nbsp;&nbsp;</span>Segmented Tables</a></span></li><li><span><a href=\"#Scripts\" data-toc-modified-id=\"Scripts-6.3.6\"><span class=\"toc-item-num\">6.3.6&nbsp;&nbsp;</span>Scripts</a></span></li></ul></li></ul></li><li><span><a href=\"#Putting-It-All-Together\" data-toc-modified-id=\"Putting-It-All-Together-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Putting It All Together</a></span><ul class=\"toc-item\"><li><span><a href=\"#Partitioned-Database\" data-toc-modified-id=\"Partitioned-Database-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Partitioned Database</a></span></li><li><span><a href=\"#Segmented-Database\" data-toc-modified-id=\"Segmented-Database-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Segmented Database</a></span></li></ul></li><li><span><a href=\"#There's-No-Place-Like-QHOME\" data-toc-modified-id=\"There's-No-Place-Like-QHOME-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>There's No Place Like <code>QHOME</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Environment-Variables\" data-toc-modified-id=\"The-Environment-Variables-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>The Environment Variables</a></span></li><li><span><a href=\"#q-in-da-hood\" data-toc-modified-id=\"q-in-da-hood-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>q in da hood</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kdb+ is the database offering from Kx. Roughly speaking, kdb+ is what happens when q tables are persisted and then mapped back into memory for operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables in Memory and Serialization\n",
    "\n",
    "It is possible to maintain a table entirely in memory, provided you have enough physical memory to hold it. There is one problem with this from a database perspective:\n",
    "\n",
    "- An in-memory table is ephemeral – meaning that **all modifications are lost if the q process dies.**\n",
    "\n",
    "One solution is to **serialize the table to persistent storage using set or similar mechanisms**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables and Keyed Tables\n",
    "- The type of any table is `98h` and the function `meta` summarizes the column names, types and attributes in a result keyed table.\n",
    "- The type of any keyed table is `99h`, since it is a dictionary and `meta` applies exactly as with tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foreign Keys and Link Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:24:43.421180000Z",
     "start_time": "2020-11-29T16:24:43.413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c | t f  a\n",
       "--| ------\n",
       "id| j kt  \n",
       "q | j     \n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kt:([id:1001 1002 1003] s:`a`b`c; v:100 200 300)\n",
    "t:([]; id:`kt$1002 1001 1003 1001; q:100 101 102 103)\n",
    "meta t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:24:51.739222000Z",
     "start_time": "2020-11-29T16:24:51.730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v   q  \n",
       "-------\n",
       "200 100\n",
       "100 101\n",
       "300 102\n",
       "100 103\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select id.v, q from t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:27:13.784176000Z",
     "start_time": "2020-11-29T16:27:13.776Z"
    }
   },
   "source": [
    "### Serializing Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:28:01.704108000Z",
     "start_time": "2020-11-29T16:28:01.696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./Ch14/t set ([] s:`a`b`c; v:100 200 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-29T16:28:08.835Z"
    }
   },
   "outputs": [],
   "source": [
    "\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:28:21.327304000Z",
     "start_time": "2020-11-29T16:28:21.318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s v  \n",
       "-----\n",
       "a 100\n",
       "b 200\n",
       "c 300\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t:get `:./Ch14/t\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:29:04.748687000Z",
     "start_time": "2020-11-29T16:29:04.745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./Ch14/kt\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./Ch14/tk\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kt:([id:1001 1002 1003] s:`a`b`c; v:100 200 300)\n",
    "tk:([] id:1001 1002 100; s:`a`b`c; v:100 200 300)\n",
    "`:./Ch14/kt set kt\n",
    "`:./Ch14/tk set tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:29:35.796842000Z",
     "start_time": "2020-11-29T16:29:35.794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t1\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t2\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./Ch14/t1 set ([]; id:`kt$1002 1001 1003 1001; q:100 101 102 103)\n",
    "`:./Ch14/t2 set ([]; id:`kt!(exec id from tk)?1002 1001 1003 1001; q:100 101 102 103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-29T16:29:37.796Z"
    }
   },
   "outputs": [],
   "source": [
    "\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:30:01.385448000Z",
     "start_time": "2020-11-29T16:30:01.383Z"
    }
   },
   "outputs": [],
   "source": [
    "kt:get `:./Ch14/kt\n",
    "tk:get `:./Ch14/tk\n",
    "t1:get `:./Ch14/t1\n",
    "t2:get `:./Ch14/t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating on Serialized Tables\n",
    "You operate on a serialized table by loading it into memory with `get` or `\\l`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:30:33.304141000Z",
     "start_time": "2020-11-29T16:30:33.301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`t\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./Ch14/t set ([] s:`a`b`c; v:100 200 300)\n",
    "\\l ./Ch14/t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:30:38.612204000Z",
     "start_time": "2020-11-29T16:30:38.603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s v  \n",
       "-----\n",
       "a 100\n",
       "b 200\n",
       "c 300\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select from t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:31:04.395802000Z",
     "start_time": "2020-11-29T16:31:04.390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s v  \n",
       "-----\n",
       "a 100\n",
       "b 200\n",
       "c 300\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1: get `:./Ch14/t\n",
    "select from t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can perform a query on a serialized table by specifying its file handle as the table name.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:31:34.816188000Z",
     "start_time": "2020-11-29T16:31:34.813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "s v  \n",
       "-----\n",
       "a 100\n",
       "c 300\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./Ch14/t set ([] s:`a`b`c; v:100 200 300)\n",
    "select from `:./Ch14/t where s in `a`c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:31:49.845581000Z",
     "start_time": "2020-11-29T16:31:49.839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./Ch14/t upsert (`x;42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:31:56.674018000Z",
     "start_time": "2020-11-29T16:31:56.671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".[`:./Ch14/t;();,;([] s:`y`z; v:400 500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:32:08.345710000Z",
     "start_time": "2020-11-29T16:32:08.343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s v  \n",
       "-----\n",
       "x 42 \n",
       "y 400\n",
       "z 500\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select from `:./Ch14/t where s in `x`y`z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar operations are available on keyed tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The limitation to using a serialized table or keyed table is that, behind the scenes, the operations load it into memory and write it back out. Amongst other things, this means that anyone wanting to work with it must be able to fit it into memory in its entirety.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Database View"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splayed Tables\n",
    "\n",
    "Splaying **solves the memory/reload issue because a splayed table is mapped into memory**; columns are loaded on demand then memory is released when no longer needed. Tables with many columns especially benefit from splaying since most queries refer to only a handful of columns and only those columns will actually be loaded.\n",
    "\n",
    "\n",
    "A splayed table corresponds to a directory whose name is the table name. Each column list of the table is serialized into a file whose name **is** the column name.\n",
    "\n",
    "**You don’t have any choice in the names.**\n",
    "\n",
    "Big Picture (1): We think of a splayed table as a persisted form that is cut vertically along columns.\n",
    "\n",
    "Geometrically, the persisted table is 1-dimensional – there is a point for each column in the persisted image of the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Splayed Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:42:01.999539000Z",
     "start_time": "2020-11-29T16:42:01.982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t/\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       ",\".\"\n",
       "\"..\"\n",
       "\".d\"\n",
       "\"v1\"\n",
       "\"v2\"\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./Ch14/t/ set ([] v1:10 20 30; v2:1.1 2.2 3.3)\n",
    "\\ls -a ./Ch14/t/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to create a splayed table with `upsert`, or with the equivalent generalized application, using the file handle as the table name. When the file does not exist, these act like `set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:42:54.035856000Z",
     "start_time": "2020-11-29T16:42:54.031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t2/\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t3/\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./Ch14/t2/ upsert ([] v1:10 20 30; v2:1.1 2.2 3.3)\n",
    ".[`:./Ch14/t3/; (); ,; ([] v1:10 20 30; v2:1.1 2.2 3.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:43:09.696116000Z",
     "start_time": "2020-11-29T16:43:09.693Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10 20 30\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.1 2.2 3.3\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`v1`v2\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get `:./Ch14/t/v1\n",
    "get `:./Ch14/t/v2\n",
    "get `:./Ch14/t/.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:44:34.427064000Z",
     "start_time": "2020-11-29T16:44:34.415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t_mannual_v1`:./Ch14/t_mannual_v2\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/manual splay\n",
    "t:([] v1:10 20 30; v2:1.1 2.2 3.3)\n",
    "cs:cols t\n",
    "{[cname] (hsym `$\"./Ch14/t_mannual_\",string cname) set t cname} each cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:44:34.977324000Z",
     "start_time": "2020-11-29T16:44:34.968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t_mannual\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./Ch14/t_mannual set cs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are serious restrictions on what can be splayed.\n",
    "\n",
    "1. Tables can be splayed. Keyed tables **cannot.**\n",
    "\n",
    "This might seem to preclude relational capabilities since it eliminates persisting a foreign key relation. But the day is saved by link columns, which can be persisted. See §14.1.2.\n",
    "\n",
    "2. Only columns that are **simple lists or compound lists** can be splayed. By compound list we mean **a list of simple lists of uniform type.**\n",
    "\n",
    "The isn’t too limiting in practice since data often comes in a uniform format that can be readily put into simple or compound lists. Incidentally, the reason for this restriction is that working with mapped general lists would be much slower than working with simple or compound lists, especially for very large data sets. \n",
    "\n",
    "3. **All symbol columns must be enumerated.**\n",
    "\n",
    "This restriction might seem to complicate life but there are conventions and utilities that eliminate most of the pain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splayed Tables with Symbol Columns\n",
    "\n",
    "The convention for symbol columns in splayed (and partitioned) tables is that **all** symbol columns in **all** tables are enumerated over the list sym, which is serialized into the root directory.\n",
    "\n",
    "The author prefers to use a projected form of the utility `.Q.en` for enumerating symbols. Its first parameter is the file handle of the root directory (the location of the sym file) and its second parameter is the table whose symbol columns you wish enumerated. Here is a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:49:29.884844000Z",
     "start_time": "2020-11-29T16:49:29.882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t_sym/\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./Ch14/t_sym/ set .Q.en[`:./Ch14;] ([] s1:`a`b`c; v:10 20 30; s2:`x`y`z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:50:32.793415000Z",
     "start_time": "2020-11-29T16:50:32.780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ",\".\"\n",
       "\"..\"\n",
       "\".d\"\n",
       "\"s1\"\n",
       "\"s2\"\n",
       ",\"v\"\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\\ls -a ./Ch14/t_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:51:01.458218000Z",
     "start_time": "2020-11-29T16:51:01.446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`s1`v`s2\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get `:./Ch14/t_sym/.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:50:13.561556000Z",
     "start_time": "2020-11-29T16:50:13.553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s1 v  s2\n",
       "--------\n",
       "a  10 x \n",
       "b  20 y \n",
       "c  30 z \n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select from `:./Ch14/t_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:51:29.405770000Z",
     "start_time": "2020-11-29T16:51:29.403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`a`b`c`x`y`z\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\\l ./Ch14\n",
    "sym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We offer several observations on the action of `.Q.en` in this example.\n",
    "- If there is a sym list in memory, it is overwritten\n",
    "- If there is a sym list on disk it is locked and then loaded into memory\n",
    "- If no sym list exists in memory or on disk an empty one is created.\n",
    "- All symbols in all symbol columns of the table are conditionally enumerated over the sym list in memory.\n",
    "- Once the enumeration is complete the sym list in memory is serialized to the root and the file is unlocked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splayed Tables with Nested Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only nested columns that can be splayed are what we call *compound lists* – i.e., lists of simple lists of uniform type. The most common example is a list of strings, which is a list of lists of char. **A compound column is indicated by an upper case letter in the result of meta**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:55:01.587192000Z",
     "start_time": "2020-11-29T16:55:01.584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c   | t f a\n",
       "----| -----\n",
       "ci  | J    \n",
       "cstr| C    \n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta ([] ci:(1 2 3; enlist 4; 5 6); cstr:(\"abc\";enlist\"d\";\"ef\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:55:01.937256000Z",
     "start_time": "2020-11-29T16:55:01.933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./tcomp2/\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./tcomp2/ set ([] ci:(1 2 3; enlist 4; 5 6); cstr:(\"abc\";enlist\"d\";\"ef\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:55:02.301905000Z",
     "start_time": "2020-11-29T16:55:02.299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c| t f a\n",
       "-| -----\n",
       "c|      \n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta ([] c:(1;1,1;`1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:55:02.660441000Z",
     "start_time": "2020-11-29T16:55:02.652Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./tcomp_wrong/\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./tcomp_wrong/ set ([] c:(1;1,1;`1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:55:39.083606000Z",
     "start_time": "2020-11-29T16:55:39.081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c  \n",
       "---\n",
       "1  \n",
       "1 1\n",
       "`1 \n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get `:./tcomp_wrong/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:56:26.208563000Z",
     "start_time": "2020-11-29T16:56:26.194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ",\".\"\n",
       "\"..\"\n",
       "\"ci\"\n",
       "\"ci#\"\n",
       "\"cstr\"\n",
       "\"cstr#\"\n",
       "\".d\"\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\\ls -a ./tcomp2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that there are two files associated with the compound column – namely, `ci` and `ci#`. If you examine these files you will discover that the “sharp” file contains the binary data of the original list in flattened form and the non-sharp file is a serialized q list of integers representing the lengths of each sublist of the original list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:58:44.370051000Z",
     "start_time": "2020-11-29T16:58:44.367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\375 \\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\00..\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"c\"$read1 hsym `$\"./tcomp2/cstr#\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:58:45.593503000Z",
     "start_time": "2020-11-29T16:58:45.591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0xfd2000000000000000000000000000000000000000000000000000000000000000000000000..\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read1 hsym `$\"./tcomp2/cstr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:59:24.478153000Z",
     "start_time": "2020-11-29T16:59:24.470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"abc\"\n",
       ",\"d\"\n",
       "\"ef\"\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get hsym `$\"./tcomp2/cstr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One question that always arises when designing a kdb+ database is whether to store text data as symbols or strings. The advantage of symbols is that they have atomic semantics and, since they are integers under the covers once they are enumerated, processing is quite fast. The main issue with symbols is that if you make all text into symbols, your sym list gets enormous and the advantages of enumeration disappear.\n",
    "\n",
    "In contrast, strings do not pollute the sym list with one-off instances and are reasonably fast. The disadvantage is that they are not first class and you must revert to teenage years by using `like` to match them.\n",
    "\n",
    "Solution: **Only make text columns into symbols when the fields will be drawn from a small, reasonably stable domain and there is significant repetition in their use. When in doubt, start with a string column. It is much easier to convert a string column to symbols that it is to remove symbols from the sym list.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Operations on Splayed Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T17:04:22.245828000Z",
     "start_time": "2020-11-29T17:04:22.236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./t/\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./t/ set .Q.en[`:./] ([] s1:`a`b`c; v:10 20 30; s2:`x`y`z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T17:05:04.843360000Z",
     "start_time": "2020-11-29T17:05:04.835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`t\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\\l ./t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T17:05:08.212740000Z",
     "start_time": "2020-11-29T17:05:08.205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s1 v  s2\n",
       "--------\n",
       "a  10 x \n",
       "b  20 y \n",
       "c  30 z \n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select from t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T17:05:17.310124000Z",
     "start_time": "2020-11-29T17:05:17.299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`kt`t`t1`t2`t3`t_sym`tk\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\\a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T17:05:23.440013000Z",
     "start_time": "2020-11-29T17:05:23.432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c | t f a\n",
       "--| -----\n",
       "s1| s    \n",
       "v | j    \n",
       "s2| s    \n"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T17:05:31.189934000Z",
     "start_time": "2020-11-29T17:05:31.187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`s1`v`s2\n"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "98h\n"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3\n"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols t\n",
    "type t\n",
    "count t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T17:05:35.716848000Z",
     "start_time": "2020-11-29T17:05:35.709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`sym$`a`b`c\n"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T17:05:45.070094000Z",
     "start_time": "2020-11-29T17:05:45.063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`sym$`a`b`c\n"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t `s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T17:06:06.132518000Z",
     "start_time": "2020-11-29T17:06:06.123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v \n",
       "--\n",
       "30\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`sym$`a`b`c\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select v from t where s1=`c\n",
    "exec s1 from t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations on a Splayed Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of this writing (Sep 2015), the table operations available against the file handle of a splayed table are: `select`, `exec`, `upsert`, `xasc`, \\`attr# (apply an attribute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T17:07:25.493415000Z",
     "start_time": "2020-11-29T17:07:25.491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s1 v  s2\n",
       "--------\n",
       "a  10 x \n",
       "b  20 y \n",
       "c  30 z \n"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10 20 30\n"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select from `:./t\n",
    "exec v from `:./t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T17:07:37.384454000Z",
     "start_time": "2020-11-29T17:07:37.379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./t\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`v xdesc `:./t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T17:07:55.270631000Z",
     "start_time": "2020-11-29T17:07:55.268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@[`:./t; `s1; `p#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T17:08:03.304165000Z",
     "start_time": "2020-11-29T17:08:03.292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c | t f a\n",
       "--| -----\n",
       "s1| s    \n",
       "v | j    \n",
       "s2| s    \n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We point out a source of confusion to qbies. Specifically, the behavior of `update` on a splayed table that has been mapped into memory. Starting with a fresh directory `/db`, create a splayed table, map it into memory and then update it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T17:09:54.043237000Z",
     "start_time": "2020-11-29T17:09:54.034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t/\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./Ch14/t/ set .Q.en[`:./Ch14;] ([] s1:`a`b`c; v:10 20 30; s2:`x`y`z)\n",
    "\\l ./Ch14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T17:10:20.627566000Z",
     "start_time": "2020-11-29T17:10:20.624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "s1 v   s2\n",
       "---------\n",
       "a  10  x \n",
       "b  20  y \n",
       "c  300 z \n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update v:300 from `t where s1=`c\n",
    "select from t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T17:10:48.888363000Z",
     "start_time": "2020-11-29T17:10:48.881Z"
    }
   },
   "source": [
    "**Updates applied to a mapped table are only visible in the workspace and are not reflected on disk. There may be scenarios where this is useful but we advise avoiding it.**\n",
    "\n",
    "Important: **It is not possible to use built-in operations to update data in persisted splayed tables.**\n",
    "\n",
    "You read that correctly. **Kdb+ is intended to store data that is not updated or deleted once it has been written**. We shall see in the next section how to append to a splayed table, which makes it possible to process updates and deletes in a bitemporal fashion, but this capability is not available out of the box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending to a Splayed Table\n",
    "\n",
    "Since `upsert` acts as `insert` on regular (non-keyed) tables and only non-keyed tables can be splayed, we use upsert with the splayed directory name in order to append records to a splayed table on disk. This is a good thing, since `insert` doesn’t work on splayed tables. Also, because symbol columns must be enumerated for splayed tables, it is best to make rows into tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T20:54:52.668388000Z",
     "start_time": "2020-11-29T20:54:52.653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t/\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t/\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t/\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t/\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./Ch14/t/ set .Q.en[`:./Ch14;] ([] s1:`a`b`c; v:10 20 30; s2:`x`y`z)\n",
    "`:./Ch14/t/ upsert .Q.en[`:./Ch14;] ([] s1:`d`e; v:40 50; s2:`u`v)\n",
    "`:./Ch14/t/ upsert .Q.en[`:./Ch14;] enlist `s1`v`s2!(`f;60;`t)\n",
    "`:./Ch14/t/ upsert .Q.en[`:./Ch14;] flip `s1`v`s2!flip ((`g;70;`r);(`h;80;`s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T20:55:12.567500000Z",
     "start_time": "2020-11-29T20:55:12.565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s1 v  s2\n",
       "--------\n",
       "a  10 x \n",
       "b  20 y \n",
       "c  30 z \n",
       "d  40 u \n",
       "e  50 v \n",
       "f  60 t \n",
       "g  70 r \n",
       "h  80 s \n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select from `:./Ch14/t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `upsert` in this fashion to build large splayed tables incrementally. The following example can be enhanced to create a splayed table step-by-step as batches of new records arrive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:01:19.078861000Z",
     "start_time": "2020-11-29T21:01:19.066Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t_batch/\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t_batch/\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t_batch/\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch:{[rt;tn;recs] hsym[`$rt,\"/\",tn,\"/\"] upsert .Q.en[hsym `$rt;] recs}\n",
    "dayrecs:{([] dt:x; ti:asc 100?24:00:00; sym:100?`ibm`aapl; qty:100*1+100?1000)}\n",
    "appday:batch[\"./Ch14\";\"t_batch\";]\n",
    "appday (dayrecs 2015.01.01)\n",
    "appday (dayrecs 2015.01.02)\n",
    "appday (dayrecs 2015.01.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:01:31.825781000Z",
     "start_time": "2020-11-29T21:01:31.817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt         ti       sym  qty  \n",
       "------------------------------\n",
       "2015.01.01 00:44:52 aapl 94600\n",
       "2015.01.01 00:56:38 ibm  88500\n",
       "2015.01.01 01:05:14 aapl 97400\n",
       "2015.01.01 01:06:27 ibm  59100\n",
       "2015.01.01 01:21:44 aapl 27100\n",
       "2015.01.01 01:21:51 ibm  25900\n",
       "2015.01.01 01:39:05 ibm  63900\n",
       "2015.01.01 01:43:30 ibm  67600\n",
       "2015.01.01 01:46:47 aapl 84200\n",
       "2015.01.01 02:05:42 aapl 67500\n",
       "2015.01.01 02:38:49 aapl 6700 \n",
       "2015.01.01 03:11:09 aapl 65700\n",
       "2015.01.01 03:22:52 aapl 65700\n",
       "2015.01.01 03:34:44 ibm  70400\n",
       "2015.01.01 03:46:26 ibm  29600\n",
       "2015.01.01 04:09:35 ibm  79700\n",
       "2015.01.01 04:11:14 aapl 64200\n",
       "2015.01.01 04:27:57 aapl 11200\n",
       "2015.01.01 04:34:55 ibm  23800\n",
       "2015.01.01 04:36:32 aapl 81200\n",
       "..\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select from `:./Ch14/t_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mannual Operations On a Splayed Directory\n",
    "\n",
    "Although there are no built-in operations to update splayed tables on disk, you can perform such operations by manipulating the serialized files.\n",
    "\n",
    "**Important**\n",
    "\n",
    "The examples shown here should be used with caution, as none of the operations are atomic; they are simply file-system manipulation. Even read-only users could see inconsistent data, so things are best done when no other users are accessing the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with sym Files\n",
    "\n",
    "**Updating sym files is delicate and should be done with great care, only after you have made a complete backup of the root directory. Corrupting the sym file will almost certainly render your database useless.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splayed Tables with Link Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:19:09.981556000Z",
     "start_time": "2020-11-29T21:19:09.979Z"
    }
   },
   "outputs": [],
   "source": [
    "t1:([] c1:`c`b`a; c2: 10 20 30)\n",
    "t2:([] c3:`a`b`a`c; c4: 1. 2. 3. 4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:19:10.396888000Z",
     "start_time": "2020-11-29T21:19:10.391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`t2\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update t1link: `t1!t1[`c1]?t2[`c3] from `t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:19:20.911600000Z",
     "start_time": "2020-11-29T21:19:20.904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c     | t f  a\n",
       "------| ------\n",
       "c3    | s     \n",
       "c4    | f     \n",
       "t1link| j t1  \n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:19:23.222884000Z",
     "start_time": "2020-11-29T21:19:23.215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c3 c4 t1link\n",
       "------------\n",
       "a  1  2     \n",
       "b  2  1     \n",
       "a  3  2     \n",
       "c  4  0     \n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:20:27.967266000Z",
     "start_time": "2020-11-29T21:20:27.957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t1/\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t2/\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./Ch14/t1/ set `.Q.en[`:./Ch14;] t1\n",
    "`:./Ch14/t2/ set `.Q.en[`:./Ch14;] t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-29T21:22:13.056Z"
    }
   },
   "outputs": [],
   "source": [
    "\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:20:44.167743000Z",
     "start_time": "2020-11-29T21:20:44.153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c     | t f  a\n",
       "------| ------\n",
       "c3    | s     \n",
       "c4    | f     \n",
       "t1link| j t1  \n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\\l ./Ch14\n",
    "meta t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:21:00.765785000Z",
     "start_time": "2020-11-29T21:21:00.763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c3 c2 c4\n",
       "--------\n",
       "a  30 1 \n",
       "b  20 2 \n",
       "a  30 3 \n",
       "c  10 4 \n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select c3, t1link.c2,c4 from t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we redo this example, assuming that the tables have already been splayed. You could map the database into memory but let’s work directly with the files. We have the additional step of appending the link columns to the `.d` file for `t2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:26:24.317109000Z",
     "start_time": "2020-11-29T21:26:24.303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t1_2/\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t2_2/\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./Ch14/t1_2/ set .Q.en[`:./Ch14;] ([] c1:`c`b`a; c2: 10 20 30)\n",
    "`:./Ch14/t2_2/ set .Q.en[`:./Ch14;] ([] c3:`a`b`a`c; c4: 1. 2. 3. 4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:26:24.935489000Z",
     "start_time": "2020-11-29T21:26:24.926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t2_2/t1link\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./Ch14/t2_2/t1link set `t1_2!(get `:./Ch14/t1_2/c1)?get `:./Ch14/t2_2/c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:26:25.406296000Z",
     "start_time": "2020-11-29T21:26:25.397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./Ch14/t2_2/.d\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".[`:./Ch14/t2_2/.d;();,;`t1link]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:27:16.369180000Z",
     "start_time": "2020-11-29T21:27:16.360Z"
    }
   },
   "outputs": [],
   "source": [
    "\\l ./Ch14/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:27:26.398081000Z",
     "start_time": "2020-11-29T21:27:26.389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c     | t f    a\n",
       "------| --------\n",
       "c3    | s       \n",
       "c4    | f       \n",
       "t1link| j t1_2  \n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta t2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:27:42.166866000Z",
     "start_time": "2020-11-29T21:27:42.159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c3 c4 t1link\n",
       "------------\n",
       "a  1  2     \n",
       "b  2  1     \n",
       "a  3  2     \n",
       "c  4  0     \n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select from t2_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Execution on Splayed Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioned Tables\n",
    "\n",
    "Some timeseries data is so large that even the individual columns may not fit into memory – for example, daily trades and quotes for an entire exchange. In this case, we can further decompose the table by slicing horizontally – called partitioning in kdb+. For example, the solution for trades and quotes is to slice into daily portions. The result is a collection of daily splayed directories, one for each day for which data exists.\n",
    "\n",
    "**All partitioned tables are splayed but not all splayed tables are partitioned.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitions\n",
    "\n",
    "A *partitioned* table is a splayed table that is further decomposed by grouping records having common values along a column of special type. The allowable special column types have the property that the underlying value is an integer: date, month, year and long.\n",
    "\n",
    "The slice of records having a given value is splayed into a directory, called a partition, whose name is that common value. In the canonical finance example, historical trades (or quotes) are stored in daily partition directories – remember a q date is an integer under the covers.\n",
    "\n",
    "**Big Picture (2)**: We think of a partitioned table as a two-dimensional persisted form since it is cut in two directions: vertically by splaying along columns and horizontally by slicing into partitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "/root\n",
    "    /partitionvalue1\n",
    "        /tablename\n",
    "            .d\n",
    "            column1name\n",
    "            column2name\n",
    "            …\n",
    "    /partitionvalue2\n",
    "        /tablename\n",
    "            .d\n",
    "            column1name\n",
    "            column2name\n",
    "            …\n",
    "        …\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**\n",
    "\n",
    "Since a partition directory name factors out the common value for all records in its slice, **do not include the partition column when you splay a partition slice – e.g., do not include a date column for a daily partitioned table.** Instead, kdb+ infers the name, value and type from the partition directory name and creates a virtual column from this information. The name of the virtual column is set by q and cannot be controlled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition Domain\n",
    "\n",
    "We call the type of the virtual column for the partition the partition domain. As noted previously, the partition domain must have an underlying integral value.\n",
    "\n",
    "**You cannot use a symbol column as a partition domain, even if the symbols are enumerated.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Partitioned Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:40:53.206613000Z",
     "start_time": "2020-11-29T21:40:53.203Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./db/2015.01.01/t/\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db/2015.01.02/t/\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./db/2015.01.01/t/ set ([] ti:09:30:00 09:31:00; p:101 102f)\n",
    "`:./db/2015.01.02/t/ set ([] ti:09:30:00 09:31:00; p:101.5 102.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:43:34.504501000Z",
     "start_time": "2020-11-29T21:43:34.497Z"
    }
   },
   "outputs": [],
   "source": [
    "\\l ./db\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-29T21:40:43.390Z"
    }
   },
   "source": [
    "The table appears to be in the workspace, along with the virtual date columns, but this is an illusion. It is actually mapped into memory. The request to display `t` forces all columns for all days to be loaded into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**\n",
    "\n",
    "Always qualify the partition column in the first where sub-phrase in any query against a partitioned table. If you do not, you will cause all partitions to be loaded into memory and will probably live-lock the server. Well before this completes, your colleagues will be at your desk with pitchforks and burning torches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:43:37.531586000Z",
     "start_time": "2020-11-29T21:43:37.520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       ti       p    \n",
       "-------------------------\n",
       "2015.01.01 09:30:00 101  \n",
       "2015.01.01 09:31:00 102  \n",
       "2015.01.02 09:30:00 101.5\n",
       "2015.01.02 09:31:00 102.5\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select from t where date within 2015.01.01 2015.01.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we partition tables with symbols in a fresh `/db.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:45:00.246078000Z",
     "start_time": "2020-11-29T21:45:00.233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./db/2015.01.01/t/\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db/2015.01.02/t/\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "date       ti       s    p    \n",
       "------------------------------\n",
       "2015.01.01 09:30:00 ibm  101  \n",
       "2015.01.01 09:31:00 msft 33   \n",
       "2015.01.02 09:30:00 ibm  101.5\n",
       "2015.01.02 09:31:00 msft 33.5 \n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./db/2015.01.01/t/ set .Q.en[`:./db;] ([] ti:09:30:00 09:31:00; s:`ibm`msft; p:101 33f)\n",
    "`:./db/2015.01.02/t/ set .Q.en[`:./db;] ([] ti:09:30:00 09:31:00; s:`ibm`msft; p:101.5 33.5)\n",
    "\\l ./db\n",
    "select from t where date within 2015.01.01 2015.01.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Partitioned Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:45:30.199378000Z",
     "start_time": "2020-11-29T21:45:30.197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:45:33.072878000Z",
     "start_time": "2020-11-29T21:45:33.065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c   | t f a\n",
       "----| -----\n",
       "date| d    \n",
       "ti  | v    \n",
       "s   | s    \n",
       "p   | f    \n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:45:37.803929000Z",
     "start_time": "2020-11-29T21:45:37.796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`date`ti`s`p\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:45:39.305797000Z",
     "start_time": "2020-11-29T21:45:39.298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98h\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, none of the following work on partitioned tables, even though they work on splayed tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:46:33.579104000Z",
     "start_time": "2020-11-29T21:46:33.572Z"
    }
   },
   "outputs": [],
   "source": [
    "/ t[0j]\n",
    "/ t[;`p]\n",
    "/ 0#t\n",
    "/ exec from t\n",
    "/ select [1] from t\n",
    "/ `p xasc t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: The fact that `exec` doesn’t work on partitioned tables is annoying but the workaround is,\n",
    "\n",
    "`exec … from select … from … `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `select` template, or the equivalent functional form, is **the** way to access data for a partitioned table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:47:37.298840000Z",
     "start_time": "2020-11-29T21:47:37.290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       ti       s    p  \n",
       "----------------------------\n",
       "2015.01.01 09:30:00 ibm  101\n",
       "2015.01.01 09:31:00 msft 33 \n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select from t where date=2015.01.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:47:47.634807000Z",
     "start_time": "2020-11-29T21:47:47.623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       ti       s    p  \n",
       "----------------------------\n",
       "2015.01.01 09:30:00 ibm  101\n",
       "2015.01.01 09:31:00 msft 33 \n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "date       ti       s    p    \n",
       "------------------------------\n",
       "2015.01.02 09:30:00 ibm  101.5\n",
       "2015.01.02 09:31:00 msft 33.5 \n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select from t where date=first date\n",
    "select from t where date=max date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:48:08.634606000Z",
     "start_time": "2020-11-29T21:48:08.632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       ti       s   p  \n",
       "---------------------------\n",
       "2015.01.01 09:30:00 ibm 101\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select from t where date=2015.01.01, ti<09:30:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:48:10.246921000Z",
     "start_time": "2020-11-29T21:48:09.840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date      | hi    lo  \n",
       "----------| ----------\n",
       "2015.01.01| 101   33  \n",
       "2015.01.02| 101.5 33.5\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select hi:max p, lo:min p by date from t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Virtual Column `i` in Partitioned Tables\n",
    "\n",
    "In a partitioned table, the virtual column `i` does not refer to absolute row number as it does with in-memory and splayed tables. Instead, it refers to the relative row number within a partition. Thus, a constraint on `i` alone would apply across all partitions and the result will contain that row in each partition slice – probably not what you want and almost certainly a bad idea (colleagues with pitchforks again).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:50:02.607017000Z",
     "start_time": "2020-11-29T21:50:02.599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       ti       s   p    \n",
       "-----------------------------\n",
       "2015.01.01 09:30:00 ibm 101  \n",
       "2015.01.02 09:30:00 ibm 101.5\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select from t where date in 2015.01.01 2015.01.02, i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:50:04.795928000Z",
     "start_time": "2020-11-29T21:50:04.792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       ti       s   p  \n",
       "---------------------------\n",
       "2015.01.01 09:30:00 ibm 101\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select from t where date=first date, i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T21:50:18.891806000Z",
     "start_time": "2020-11-29T21:50:18.884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       ti       s    p   \n",
       "-----------------------------\n",
       "2015.01.02 09:31:00 msft 33.5\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select from t where date=max date, i=max i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Execution on Partitioned Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyze the where phrase to determine which partition slices are targeted by the query\n",
    "- Process the remaining where sub-phrases to determine the column sub-domains that must be loaded.\n",
    "- Process the query separately against the requisite partition slices to obtain partial results.\n",
    "- Combine the partial results to obtain the final result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map-Reduce\n",
    "\n",
    "map-reduce decomposes an operation on a (presumably large) list into two suboperations, opmap and opreduce. In the first step, called 'map', opmap is performed on each sublist to obtain a list of partial results. In the second step, called \"reduce\", the partial result lists are combined with opreduce to obtain the final result. A good exercise (and interview question) is to express sorting a list using map-reduce. In greater generality, map-reduce may apply the two steps recursively – i.e., the reduce step may itself involve a map-reduce, etc.\n",
    "\n",
    "At the time of this writing (Sep 2015), the aggregates that kdb+ can decompose with map-reduce are: `avg`, `cor`, `count`, `cov`, `dev`, `distinct`, `first`, `last`, `max`, `med`, `min`, `prd`, `sum`, `var`, `wavg`, `wsum`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Partitioned Tables\n",
    "\n",
    "Recall that there can be only one partition domain in a given kdb+ root – i.e., daily, monthly, yearly or long. However, multiple tables can share this partitioning.\n",
    "\n",
    "```\n",
    "/db\n",
    "    /2015.01.01\n",
    "        /trade\n",
    "        /quote\n",
    "    /2015.01.02\n",
    "        /trade\n",
    "        /quote\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: \n",
    "\n",
    "Although not all potential partition values need be populated, any value that is populated must contain slices for all tables. The following layout is in error.\n",
    "```\n",
    "/db\n",
    "    /2015.01.01 <- this is a bad partition!\n",
    "        /quote\n",
    "    /2015.01.02\n",
    "        /trade\n",
    "        /quote\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-29T22:20:19.442Z"
    }
   },
   "outputs": [],
   "source": [
    "\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:20:25.176468000Z",
     "start_time": "2020-11-29T22:20:23.691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./db/2015.01.01/q/\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db/2015.01.02/q/\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./db/2015.01.01/q/ set .Q.en[`:./db;]\n",
    " ([] ti:09:30:00 09:31:00; sym:`ibm`msft;b:100.75 32.75; a:101.25 33.25f)\n",
    "`:./db/2015.01.02/q/ set .Q.en[`:./db;]\n",
    " ([] ti:09:30:00 09:30:00; sym:`ibm`msft;b:101.25 33.25; a:101.75 33.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:20:26.991824000Z",
     "start_time": "2020-11-29T22:20:26.990Z"
    }
   },
   "outputs": [],
   "source": [
    "\\l ./db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:20:27.573780000Z",
     "start_time": "2020-11-29T22:20:27.564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       ti       s    p    \n",
       "------------------------------\n",
       "2015.01.01 09:30:00 ibm  101  \n",
       "2015.01.01 09:31:00 msft 33   \n",
       "2015.01.02 09:30:00 ibm  101.5\n",
       "2015.01.02 09:31:00 msft 33.5 \n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select from t where date within 2015.01.01 2015.01.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:20:28.124489000Z",
     "start_time": "2020-11-29T22:20:28.115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       ti       sym  b      a     \n",
       "--------------------------------------\n",
       "2015.01.01 09:30:00 ibm  100.75 101.25\n",
       "2015.01.01 09:31:00 msft 32.75  33.25 \n",
       "2015.01.02 09:30:00 ibm  101.25 101.75\n",
       "2015.01.02 09:30:00 msft 33.25  33.75 \n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select from q where date within 2015.01.01 2015.01.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:22:30.678990000Z",
     "start_time": "2020-11-29T22:22:30.670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./db/2014.12.31/q/\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./db/2014.12.31/q/ set .Q.en[`:./db;]\n",
    " ([] ti:09:30:00 09:31:00; sym:`ibm`msft; b:101. 33.; a:101.5 33.5f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:22:40.225806000Z",
     "start_time": "2020-11-29T22:22:40.219Z"
    }
   },
   "outputs": [],
   "source": [
    "\\l ./db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:22:40.895274000Z",
     "start_time": "2020-11-29T22:22:40.886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       ti       sym  b   a    \n",
       "----------------------------------\n",
       "2014.12.31 09:30:00 ibm  101 101.5\n",
       "2014.12.31 09:31:00 msft 33  33.5 \n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select from q where date=2014.12.31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " a nasty surprise when we query `t` on the missing date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:22:42.067416000Z",
     "start_time": "2020-11-29T22:22:42.065Z"
    }
   },
   "outputs": [
    {
     "ename": "\u001b[0;31m./2014.12.31/t/ti. OS reports: No such file or directory\u001b[0m",
     "evalue": "\u001b[0;31m./2014.12.31/t/ti. OS reports: No such file or directory\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31mevaluation error:\n\u001b[0m",
      "\u001b[0;31m./2014.12.31/t/ti. OS reports: No such file or directory\u001b[0m",
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31m  [4]  (.Q.p2)\n\n\u001b[0m",
      "\u001b[0;31m  [3]  (.Q.p)\n\n\u001b[0m",
      "\u001b[0;31m  [2]  (.Q.foo)\n\n\u001b[0m",
      "\u001b[0;31m  [1]  (.Q.ps)\n\n\u001b[0m",
      "\u001b[0;31m  [0]  select from t where date=2014.12.31\n       ^\n\u001b[0m"
     ]
    }
   ],
   "source": [
    "select from t where date=2014.12.31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could remedy this by splaying an empty copy of `t` on that date. Instead we use the utility `.Q.chk` that fills all missing slices with empty tables from the most recent partition. We remap and find things are fine.\n",
    "\n",
    "**Tip**\n",
    "\n",
    "If you neglect to place a table slice in the most recent partition, the table will effectively disappear from your database since kdb+ inspects only that partition to determine which tables are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:23:19.119506000Z",
     "start_time": "2020-11-29T22:23:19.109Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()\n",
       "()\n",
       ",`:.//2014.12.31\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".Q.chk `:./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:23:34.635243000Z",
     "start_time": "2020-11-29T22:23:34.627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date ti s p\n",
       "-----------\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select from t where date=2014.12.31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing with our previous (repaired) example we add a trade slice for 2015.01.03 but neglect to add a quotes slice. When we remap, the table `q` is nowhere to be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:33:22.778856000Z",
     "start_time": "2020-11-29T22:33:22.770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./db/2015.01.03/t/\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./db/2015.01.03/t/ set .Q.en[`:./db;] ([] ti:09:30:00 09:31:00; sym:`ibm`msft;p:101 33f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:33:45.138357000Z",
     "start_time": "2020-11-29T22:33:45.132Z"
    }
   },
   "outputs": [],
   "source": [
    "\\l ./db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:33:46.025985000Z",
     "start_time": "2020-11-29T22:33:46.022Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       ti       sym  p  \n",
       "----------------------------\n",
       "2015.01.03 09:30:00 ibm  101\n",
       "2015.01.03 09:31:00 msft 33 \n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select from t where date=2015.01.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:33:48.946243000Z",
     "start_time": "2020-11-29T22:33:48.942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ",`t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\\a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:34:15.013382000Z",
     "start_time": "2020-11-29T22:34:15.011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./db/2015.01.03/q/\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./db/2015.01.03/q/ set 0#select from `:./db/2015.01.02/q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:34:27.826040000Z",
     "start_time": "2020-11-29T22:34:27.823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`q`t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\\l ./db\n",
    "\\a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of Other Partition Domain Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:36:01.079130000Z",
     "start_time": "2020-11-29T22:36:01.062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./db2/2015/t/\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db2/2014/t/\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "year date       p    \n",
       "---------------------\n",
       "2014 2014.01.01 101.5\n",
       "2014 2014.01.02 102.5\n",
       "2015 2015.01.01 101  \n",
       "2015 2015.01.02 102  \n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./db2/2015/t/ set ([] date:2015.01.01 2015.01.02; p:101 102f)\n",
    "`:./db2/2014/t/ set ([] date:2014.01.01 2014.01.02; p:101.5 102.5)\n",
    "\\l ./db2\n",
    "select from t where year within 2014 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do not include a trailing / in the partition directory name but do include it in the queries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:41:56.340499000Z",
     "start_time": "2020-11-29T22:41:56.334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./db3/2015.01/t/\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db3/2015.02/t/\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./db3/2015.01/t/ set ([] date:2015.01.01 2015.01.02; p:101 102f)\n",
    "`:./db3/2015.02/t/ set ([] date:2015.02.01 2015.02.02; p:101.5 102.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:41:58.072795000Z",
     "start_time": "2020-11-29T22:41:58.070Z"
    }
   },
   "outputs": [],
   "source": [
    "\\l ./db3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:41:58.841414000Z",
     "start_time": "2020-11-29T22:41:58.839Z"
    }
   },
   "outputs": [
    {
     "ename": "\u001b[0;31mparse error\u001b[0m",
     "evalue": "\u001b[0;31m2015.01m\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31mparse error\u001b[0m",
      "\u001b[0;31m2015.01m\u001b[0m"
     ]
    }
   ],
   "source": [
    "select from t where month within 2015.01m 2015.02m /cannot work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-29T22:42:13.611Z"
    }
   },
   "source": [
    "You can partition by a long to slice into arbitrary bins. The data need not be daily. In a fresh `/db`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:42:45.124084000Z",
     "start_time": "2020-11-29T22:42:45.121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./db4/1/t/\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db4/2/t/\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./db4/1/t/ set ([] ti:09:30:00 09:31:00; p:101 102f)\n",
    "`:./db4/2/t/ set ([] ti:09:30:00 09:31:00; p:101.5 102.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T22:42:56.407494000Z",
     "start_time": "2020-11-29T22:42:56.399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int ti       p    \n",
       "------------------\n",
       "1   09:31:00 102  \n",
       "2   09:31:00 102.5\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\\l ./db4\n",
    "select from t where i within 1 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioned Tables with Links\n",
    "\n",
    "A link column in the slice of a partitioned table must be intra-partition – i.e., it must refer to another table in the same slice. In particular, you cannot link across days in a daily partitioned database.\n",
    "\n",
    "Since the daily slices are splayed tables, the mechanics of creating links for partitioned tables are the same as for splayed tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T11:48:44.068308000Z",
     "start_time": "2020-11-30T11:48:44.064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./db5/2015.01.01/t1/\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db5/2015.01.01/t2/\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db5/2015.01.02/t1/\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db5/2015.01.02/t2/\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1:([] id:101 102 103; v:1.1 2.2 3.3)\n",
    "`:./db5/2015.01.01/t1/ set t1\n",
    "`:./db5/2015.01.01/t2/ set ([] id:`t1!t1[`id]?103 101 101 102;n:10 20 30 40)\n",
    "`:./db5/2015.01.02/t1/ set t1\n",
    "`:./db5/2015.01.02/t2/ set ([] id:`t1!t1[`id]?105 104 104; n:50 60 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T11:48:56.935805000Z",
     "start_time": "2020-11-30T11:48:56.933Z"
    }
   },
   "outputs": [],
   "source": [
    "\\l ./db5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T11:49:17.877530000Z",
     "start_time": "2020-11-30T11:49:17.873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       n  v  \n",
       "-----------------\n",
       "2015.01.01 10 3.3\n",
       "2015.01.01 20 1.1\n",
       "2015.01.01 30 1.1\n",
       "2015.01.01 40 2.2\n",
       "2015.01.02 50    \n",
       "2015.01.02 60    \n",
       "2015.01.02 70    \n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select date,n, id.v from t2 where date in 2015.01.01 2015.01.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a link column to persisted partitions is only a bit more complicated. Here we create a link on (enumerated) symbol columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T11:50:51.936298000Z",
     "start_time": "2020-11-30T11:50:51.931Z"
    }
   },
   "outputs": [],
   "source": [
    "\\cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T11:51:03.615965000Z",
     "start_time": "2020-11-30T11:51:03.603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./db6/2015.01.01/t1/\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db6/2015.01.02/t1/\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db6/2015.01.01/t2/\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db6/2015.01.02/t2/\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./db6/2015.01.01/t1/ set .Q.en[`:./db6;] ([] id:`c`b`a; c1: 10 20 30)\n",
    "`:./db6/2015.01.02/t1/ set .Q.en[`:./db6;] ([] id:`x`a; c1: 40 50)\n",
    "`:./db6/2015.01.01/t2/ set .Q.en[`:./db6;] ([] id:`a`b`a`c; c2: 1 2 3 4.)\n",
    "`:./db6/2015.01.02/t2/ set .Q.en[`:./db6;] ([] id:`x`a`x; c2:5 6 7.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presumably at a later time, we add the link column to `t2` in each partition, making sure to update the `.d` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T11:52:51.253039000Z",
     "start_time": "2020-11-30T11:52:51.249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./db6/2015.01.01/t2/t1lnk\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db6/2015.01.01/t2/.d\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db6/2015.01.02/t2/t1lnk\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db6/2015.01.02/t2/.d\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./db6/2015.01.01/t2/t1lnk set `t1!get[`:./db6/2015.01.01/t1/id]?get[`:./db6/2015.01.01/t2/id]\n",
    "`:./db6/2015.01.01/t2/.d set get[`:./db6/2015.01.01/t2/.d],`t1lnk\n",
    "`:./db6/2015.01.02/t2/t1lnk set `t1!get[`:./db6/2015.01.02/t1/id]?get[`:./db6/2015.01.02/t2/id]\n",
    "`:./db6/2015.01.02/t2/.d set get[`:./db6/2015.01.02/t2/.d],`t1lnk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T11:53:05.795571000Z",
     "start_time": "2020-11-30T11:53:05.792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       id c1 c2\n",
       "-------------------\n",
       "2015.01.01 a  30 1 \n",
       "2015.01.01 b  20 2 \n",
       "2015.01.01 a  30 3 \n",
       "2015.01.01 c  10 4 \n",
       "2015.01.02 x  40 5 \n",
       "2015.01.02 a  50 6 \n",
       "2015.01.02 x  40 7 \n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\\l ./db6\n",
    "select date,id,t1lnk.c1,c2 from t2 where date<=2015.01.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmented Tables\n",
    "\n",
    "In large timeseries databases, the queries are often I/O-bound. In this case, the multiple slaves for a partitioned query will mostly be waiting on I/O (or Godot). The solution requires multiple I/O channels so that data retrieval and processing can occur in parallel. Kdb+ provides another level of data decomposition to enable parallel processing in this scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segments\n",
    "\n",
    "Segmentation is an additional level of structure on top of partitioning. Segmentation spreads a partitioned table’s records across multiple directories that have the same structure as the root directory in a partitioned database. Each pseudo-root, called a segment, is thus a directory that contains a collection of partition directories. The segment directories are presumably on independent I/O channels so that data retrieval can occur in parallel.\n",
    "\n",
    "**You must ensure that the segments conform and are complete and disjoint, since kdb+ will not check this when you write the data files. In particular, overlapping segments will result in duplicate records in query results and an incomplete decomposition will result in dropped records.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Big Picture (3)**: .We view a segmented table as a three-dimensional persisted form: the table is cut vertically by splaying, sliced horizontally by partitions and is additionally segmented across physical locations. **The primary purpose of the third dimension is to allow operations against the tables to take advantage of parallel I/O and concurrent processing.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to the partitioned table layout in which partitions reside under the root, the segment directories must **not** reside under the root. The only portion of a segmented table (other than the sym file for enumerated symbol columns) that lives in the root is a file called `par.txt` containing the paths of the physical locations of the segments, one segment path per line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "/db\n",
    "    [sym]\n",
    "    par.txt\n",
    "=============== <- channel 1\n",
    "/segment1\n",
    "    /partition*\n",
    "        /table*\n",
    "        /table*\n",
    "        …\n",
    "    /partition*\n",
    "        /table*\n",
    "        /table*\n",
    "        …\n",
    "=============== <- channel 2\n",
    "/segment2\n",
    "    /partition*\n",
    "        /table*\n",
    "        /table*\n",
    "        …\n",
    "    /partition*\n",
    "        /table*\n",
    "        /table*\n",
    "        …\n",
    "=============== …\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentation can be achieved by splitting the daily slices into records with symbols starting with a-m and those starting with n-z, or trades from NYSE and trades from NASDAQ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation vs. Partitions\n",
    "![](../data/pic/ch14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Segmented Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no one-size-fits-all utility to create segments. Instead, you write a q program that places a subset of each partition slice into a segment. You can create segments and partitions at the same time by including logic in your data load script to extract slice subsets and place them in the appropriate directory on the appropriate drive.\n",
    "\n",
    "Along with creating the partitions, you must also specify the locations of the segments in an ASCII text file `par.txt` located in the root. Each line of `par.txt` contains the path of one segment directory; symlinks are acceptable.\n",
    "\n",
    "**The segment paths must not be under the root**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accross days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T12:14:15.582334000Z",
     "start_time": "2020-11-30T12:14:15.571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./db/1/2015.01.01/t/\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db/2/2015.01.02/t/\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db/1/2015.01.03/t/\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db/2/2015.01.04/t/\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db/par.txt\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`:./db/1/2015.01.01/t/ set .Q.en[`:./db;] ([] ti:09:30:00 09:31:00; s:`ibm`t; p:101 17f)\n",
    "`:./db/2/2015.01.02/t/ set .Q.en[`:./db;] ([] ti:09:30:00 09:31:00; s:`ibm`t; p:101.5 17.5)\n",
    "`:./db/1/2015.01.03/t/ set .Q.en[`:./db;] ([] ti:09:30:00 09:31:00; s:`ibm`t; p:103 16.5f)\n",
    "`:./db/2/2015.01.04/t/ set .Q.en[`:./db;] ([] ti:09:30:00 09:31:00; s:`ibm`t; p:102 17f)\n",
    "`:./db/par.txt 0: (\"/1\"; \"/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T12:14:27.206964000Z",
     "start_time": "2020-11-30T12:14:27.204Z"
    }
   },
   "outputs": [
    {
     "ename": "\u001b[0;31mpart\u001b[0m",
     "evalue": "\u001b[0;31mpart\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31mevaluation error:\n\u001b[0m",
      "\u001b[0;31mpart\u001b[0m",
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31m  [2]  (.Q.L)\n\n\u001b[0m",
      "\u001b[0;31m  [1]  (.Q.l)\n\n\u001b[0m",
      "\u001b[0;31m  [0]  \\l ./db\n       ^\n\u001b[0m"
     ]
    }
   ],
   "source": [
    "\\l ./db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T12:14:30.390001000Z",
     "start_time": "2020-11-30T12:14:30.382Z"
    }
   },
   "outputs": [
    {
     "ename": "\u001b[0;31mt\u001b[0m",
     "evalue": "\u001b[0;31mt\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31mevaluation error:\n\u001b[0m",
      "\u001b[0;31mt\u001b[0m",
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31m  [0]  select from t where date within 2015.01.01 2015.01.04\n                   ^\n\u001b[0m"
     ]
    }
   ],
   "source": [
    "select from t where date within 2015.01.01 2015.01.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T12:17:38.881250000Z",
     "start_time": "2020-11-30T12:17:38.877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/vincentwang/Desktop/q/q4m/segment/db\"\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\\pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T12:17:40.679822000Z",
     "start_time": "2020-11-30T12:17:40.677Z"
    }
   },
   "outputs": [],
   "source": [
    "\\cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Across symbols** \n",
    "\n",
    "```\n",
    "/am\n",
    "    /2015.01.01\n",
    "    /2015.01.02\n",
    "/nz\n",
    "    /2015.01.01\n",
    "    /2015.01.02\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T12:24:39.608563000Z",
     "start_time": "2020-11-30T12:24:39.598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:./db2/am/2015.01.01/t/\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db2/nz/2015.01.01/t/\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db2/am/2015.01.02/t/\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db2/nz/2015.01.02/t/\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:./db2/par.txt\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extr:{[t;r] select from t where (`$1#'string sym) within r}\n",
    "t1:.Q.en[`:./db2;] ([] ti:09:30:00 09:31:00; sym:`ibm`t; p:101 17f)\n",
    "`:./db2/am/2015.01.01/t/ set extr[t1;`a`m]\n",
    "`:./db2/nz/2015.01.01/t/ set extr[t1;`n`z]\n",
    "t2:.Q.en[`:./db2;] ([] ti:09:30:00 09:31:00; sym:`ibm`t; p:101.5 17.5)\n",
    "`:./db2/am/2015.01.02/t/ set extr[t2;`a`m]\n",
    "`:./db2/nz/2015.01.02/t/ set extr[t2;`n`z]\n",
    "`:./db2/par.txt 0: (\"/am\"; \"/nz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T12:24:42.070956000Z",
     "start_time": "2020-11-30T12:24:42.067Z"
    }
   },
   "outputs": [
    {
     "ename": "\u001b[0;31mempty\u001b[0m",
     "evalue": "\u001b[0;31mempty\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31mevaluation error:\n\u001b[0m",
      "\u001b[0;31mempty\u001b[0m",
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31m  [2]  (.Q.L)\n\n\u001b[0m",
      "\u001b[0;31m  [1]  (.Q.l)\n\n\u001b[0m",
      "\u001b[0;31m  [0]  \\l ./db2\n       ^\n\u001b[0m"
     ]
    }
   ],
   "source": [
    "\\l ./db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T12:24:43.330295000Z",
     "start_time": "2020-11-30T12:24:43.327Z"
    }
   },
   "outputs": [
    {
     "ename": "\u001b[0;31mt\u001b[0m",
     "evalue": "\u001b[0;31mt\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31mevaluation error:\n\u001b[0m",
      "\u001b[0;31mt\u001b[0m",
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31m  [0]  select from t where date within 2015.01.01 2015.01.02\n                   ^\n\u001b[0m"
     ]
    }
   ],
   "source": [
    "select from t where date within 2015.01.01 2015.01.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T12:24:44.264069000Z",
     "start_time": "2020-11-30T12:24:44.260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/vincentwang/Desktop/q/q4m/segment/db2\"\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\\pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T12:24:52.570512000Z",
     "start_time": "2020-11-30T12:24:52.568Z"
    }
   },
   "outputs": [],
   "source": [
    "\\cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other segment type:\n",
    "\n",
    "```\n",
    "/nyse\n",
    "    /2015.01.01\n",
    "        /t\n",
    "    /2015.01.02\n",
    "        /t\n",
    "/nasd\n",
    "    /2015.01.01\n",
    "        /t\n",
    "    /2015.01.02\n",
    "        /t\n",
    "```\n",
    "\n",
    "```\n",
    "/seg A\n",
    "    /2015.01.01\n",
    "    /2015.01.02\n",
    "/seg B\n",
    "    /2015.01.02\n",
    "    /2015.01.03\n",
    "/seg C\n",
    "    /2015.01.04\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Segmented Tables\n",
    "```\n",
    "/a_m <- segment for first portion of alphabet\n",
    "    /2015.01.01     <- the specific day\n",
    "        /t          <- that day’s trades for symbols a-m\n",
    "        /q          <- that day’s quotes for symbols a-m\n",
    "    /2015.01.02     <- the specific day\n",
    "        /t          <- that day’s trades for symbols a-m\n",
    "        /q          <- that day’s quotes for symbols a-m\n",
    "=================\n",
    "/n_z                <- segment for second portion of alphabet\n",
    "    /2015.01.01     <- the specific day\n",
    "        /t          <- that day’s trades for symbols n-z\n",
    "        /q          <- that day’s quotes for symbols n-z\n",
    "    /2015.01.02     <- the specific day\n",
    "        /t          <- that day’s trades for symbols n-z\n",
    "        /q          <- that day’s quotes for symbols n-z\n",
    "=================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s do the `aj`. We could be naïve and pull all requisite data into the workspace, but this would be inefficient in memory and slow, assuming it would fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aj[`date`sym`ti;select from t where date within dr;\n",
    "select from q where date within dr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead we start q with slaves and use `peach` to run things in parallel across the segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$q -s 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aj1:{aj[`sym`ti;select from t where date=d; select from q where date=d]}\n",
    "raze aj1 peach 2015.01.01 2015.01.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Execution against Segmented Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance goal is to **scale out by taking advantage of parallel I/O and concurrent processing**. We would ideally like to **achieve 100% saturation of the I/O channels and 100% utilization of each core**. How do we approach these levels on a kdb+ server? The key insight in kdb+ design and tuning is that **a vector calculation on in-memory data is much faster than retrieving data from storage**. This suggests our first two design principles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Maximize the number of independent I/O channels to retrieve data in parallel.\n",
    "\n",
    "2. Maximize server memory in order to allocate each slave thread as much memory as it needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we can satisfy these two objectives by having storage devices attached to the kdb+ server over n independent I/O channels – for example, the author’s laptop has SSD storage that appears as multiple independent I/O channels. In this scenario, we are led to our next observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create n segments to spread data retrieval across the n channels in order to maximize I/O parallelization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that data can be processed from all n channels simultaneously and that no two threads contend for data, we are led to our final objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Have (at least) n slave threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now assuming we have such an environment, does kdb+ execute a query against a segmented table in our scenario of n segments and n slaves.? Essentially, it decomposes a qualifying query into two steps via **map-reduce**:\n",
    "- Map: a revised form of the original query that executes on each segment\n",
    "- Reduce: aggregate the segment results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing Slaves and Cores\n",
    "\n",
    "We now investigate channel and core utilization. Since kdb+ will only use as many slaves to process a query as there are segments in the query footprint, we consider two cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I/O-bound**: Assuming that the query has _light calculation compared to data retrieval (common in kdb+)_, having n slaves on n cores is close to optimal: most of the time, all n slaves will be waiting for data. When a partition load completes, there will be a brief burst of computation, followed by another long load. So we conclude for this scenario:\n",
    "\n",
    "**n channels => n segments => n slaves => n cores**\n",
    "\n",
    "**Balanced I/O-compute**: Consider the scenario in which both the I/O and calculation are intensive. While one slave is waiting on data, another slave on the same core could be crunching; conversely, **while one slave is crunching another slave on that core could be loading data**. Thus to maximize channel and core utilization, we actually want 2n slaves on n cores. We conclude that in this scenario we should have 2n segments, two per channel. On average, there will be one slave per core loading data and one slave per core crunching the data it has just loaded.\n",
    "\n",
    "n channels => 2n segments => 2n slaves => n cores\n",
    "\n",
    "These conclusions rely on many implicit assumptions that we have glossed over. In practice, you should view them as guidelines, with the goal of feeding data to kdb+ as fast as possible. The optimum configuration for your situation will depend on your particular query mix. **For example, queries that do VWAP calculations are closer to the first scenario, whereas queries doing regression analysis are closer to the second.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good strategy is to **construct your initial configuration using one of the above scenarios**. Then load a good approximation of your anticipated data and query mix, and simulate a realistic user load. Observe the I/O saturation and CPU utilization and adjust the number of slaves and cores allocated to the q process accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Performance Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities for Splaying and Partitioning\n",
    "\n",
    "The `.Q namespace` contains useful functions for creating and maintaining splayed and partitioned tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.Q.qp`\n",
    "\n",
    "The unary `.Q.qp` asks the residency of its table argument. It returns `1b` if its argument is a partitioned table mapped into memory, `0b` if it is splayed and 0 for anything else. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.Q.en`\n",
    "The binary `.Q.en` takes a **symbolic file handle of a root directory as its first argument and a table as its second argument**. As a side effect, it creates a list sym comprising the unique items across all symbol columns and writes it to an eponymous file in the specified directory. It returns a table obtained from the original table by enumerating its symbol column(s) over sym."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More detail on the actual sequence of operations for `.Q.en`.:\n",
    "\n",
    "- The variable `sym` is created (in memory) by loading the file `sym` from the specified root, should such exist, or as the empty symbol list if not. An existing `sym` variable in the workspace is **overwritten** in this step.\n",
    "- All symbol columns of (a copy of) the table are conditionally enumerated over the sym list.\n",
    "- The `sym` variable is serialized to the specified root directory.\n",
    "- The enumerated table is returned from the function application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.Q.en` overwrite the previous records. How to extend it then?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.Q.pv`\n",
    "\n",
    "The variable `.Q.pv` is a list containing the values of the partition domain – i.e., the values corresponding to the slice directories actually found in the root. This is useful if you need to iterate over all the partitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.Q.ind`\n",
    "As we saw in §14.3, the virtual column `i` reflects the **relative** row number in a partitioned table. That is, the value of `i` is the offset of the records within the partition slice. How to retrieve records by absolute within a partition or segmented?\n",
    "\n",
    "A masochist might use a q expression to determine the partition and relative row for the absolute row number. It is less painful to use the binary `.Q.ind`, whose first argument is a partitioned table and whose second argument is a list of long values representing absolute row numbers. The result is a table in memory. You must enlist a single index value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.Q.dpft`\n",
    "The utility `.Q.dpft` assists in creating partitioned and segmented tables by incorporating the functionality of `.Q.en` at a slightly higher level. It is convenient when partitions are loaded and written out iteratively.\n",
    "\n",
    "The first parameter is the symbolic file handle of the database root directory. The second parameter is the q data value that will become the name of the partition subdirectory. The third parameter is the name of the field to which the \\`p# attribute is applied (usually \\`sym for trades and quotes). The last parameter is the table name.\n",
    "\n",
    "The `.Q.dpft` function rearranges (a copy of) the named table so that the partition column is first and the parted column is second, and then splays it into the specified partition in the specified directory. When appropriate, it enumerates all symbol columns over sym and saves a `sym` list in the root. The result is the table name if the operation is successful.\n",
    "\n",
    "**Notes**:\n",
    "\n",
    "- Because the final parameter is a table name, this function cannot be applied to a local variable.\n",
    "- The table columns must be simple or compound lists.\n",
    "- The source table cannot be a keyed table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.Q.fs`\n",
    "\n",
    "Splayed tables (as well as partitioned or segmented slices) are too large to fit into memory. Thus, we face the dilemma of how to create such tables, since splaying requires the table to be in memory. The utility `.Q.fs` comes to the rescue by allowing us to process text files in \"chunks.\"\n",
    "\n",
    "\n",
    "The chunk size used by `.Q.fs` is hard-coded. If this does not provide adequate performance may wish to use `.Q.fsn`, which exposes the chunk size as an additional parameter. The optimal chunk size will vary for each application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loosely speaking, `.Q.fs` applies a function to the records of a text file in “chunks” instead of processing the entire file in one gulp. It iterates the function over a number of bite-sized record lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.Q.chk`\n",
    "\n",
    "The utility `.Q.chk` is a unary function whose argument is the symbolic file handle of a root directory. It examines each partition sub-directory in the root and writes an empty splayed slice of the appropriate form wherever a table is missing in a partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.Q.view`\n",
    "\n",
    "The unary `.Q.view` is handy when you are executing queries against partitioned or segmented tables. Recall that multiple tables can share the partitioning. The argument of `.Q.view` is a list of partition values that acts as a filter for all queries against any partitioned table in the database. Otherwise put, the practical effect of applying `.Q.view` is to add its argument as a constraint in the first sub-phrase of the where clause of every query. This can guard against runaway queries that ask for all historical data, for example.\n",
    "\n",
    "To reset the default view to all partitions, invoke `.Q.view` as a nullary.\n",
    "\n",
    "You can use the partition value variable `.Q.pv` in the argument to `.Q.view`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kdb Database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing kdb+ to an RDBMS\n",
    "\n",
    "Fundamental differece:\n",
    "1. Kdb+ is based on lists, which are ordered collections allowing duplicates, whereas SQL is based on sets, which are unordered collections of distinct elements.\n",
    "\n",
    "2. Kdb+ stores data as contiguous items in column lists, whereas an RDBMS stores data as fields within non-contiguous rows. Neo in kdb+ says, “There are no rows.”\n",
    "\n",
    "3. Kdb+ table operations are vector operations on columns, whereas SQL operates on individual fields and rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../data/pic/ch14_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Physical Layout of a kdb+ Database\n",
    "\n",
    "Here is a Zen koan: What is a kdb+ database? At the most basic level, a kdb+ database is a file system directory (and sub directories) holding q entities. This directory is the root of the database. All constituents of the database are simply q entities saved in files. Database entities either reside at some level under the root or are pointed to from `par.txt` under the root."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `sym` File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sym file is an optional serialized q data file containing a list of unique symbols used as the domain for symbol enumeration.Placing the sym file in the root guarantees that it will be loaded into memory at q startup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no strict requirement that there be only one enumeration domain, but conventionally all symbol columns from all tables are enumerated over a single domain sym. The `.Q` utilities that handle symbol enumeration assume this. If you choose to have multiple enumeration domains, be aware that symbols in the resulting enumerated values will act as expected under `=` but not with `~` since they have different types. You can resolve the enumerations with `value` if this is a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**\n",
    "\n",
    "Pay very careful attention to the sym file, as it is a single point of failure. Corrupting or losing it will result in all your symbol columns being irresolvable. Good practice is to use conditional enumeration – e.g., \\`:/db/sym? – when you enumerate symbols manually or use `.Q` utilities that do this for you. Always back up your database before operating on the sym file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sym file will not normally be a choke point when loading historical data from an external source into a kdb+ because conditional enumeration (and the `.Q` utilities) use file locking to mediate concurrent updates. Alternately, if the symbol domain is known in advance, you can load the sym list into memory and use non-conditional enumeration – i.e., \\`sym$. For example, one approach is to create a preprocessing utility in Perl to extract all symbols from the source data, import this as a list in q and place the distinct items in sym. Then create the historical partitions running concurrent processes that use unconditional enumerations. Be mindful that unconditional enumeration fails for a symbol not in the domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Serialized Files in Root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it is seldom done in practice (perhaps because few kdb+ programmers are aware of the possibility), it is possible to place any serialized q entity into the root and have it loaded into an eponymous file. This can be a more efficient than using a script to initialize variables in the workspace.\n",
    "\n",
    "**If you use this, don’t go overboard. Also, it might break `.Q.en`.**\n",
    "\n",
    "One type of serialized file that can be initialized in this fashion is a reference table (or keyed table) of modest size (up to millions of rows). Such a table will be loaded into memory in its entirety, so lookups or joins on it will be quite fast.\n",
    "\n",
    "It is possible to (re)load the entire state of the root context automatically by serializing that directory and loading it in this fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scripts\n",
    "\n",
    "A script in the root can hold arbitrary q code that will be loaded upon startup. In particular, functions defined in such a script can be viewed as stored procedures for the database. While it is possible to have multiple q scripts in the root, you probably want precise control over the order in which the scripts are executed. Good practice is to keep in the root one startup script that loads scripts residing in libraries elsewhere.\n",
    "\n",
    "\n",
    "```\n",
    "/db\n",
    "    …\n",
    "    init.q\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splayed Tables\n",
    "\n",
    "Reference tables of intermediate size (up to tens of millions of rows) can be splayed under the root. Splayed table directories must be immediately under the root.\n",
    "\n",
    "#### Partitioned Tables\n",
    "#### Segmented Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Populating a kdb+ Database\n",
    "#### What happens at startup?\n",
    "\n",
    "Whatever it recognizes as its own, it does.\n",
    "\n",
    "Thus, a serialized q entity is loaded; a splayed, partitioned or segmented table is mapped; a script is executed.\n",
    "\n",
    "**Important**\n",
    "\n",
    "Almost anything that q does not recognize causes it to abort that portion of startup. In particular, if q discovers foreign or undecipherable files in splayed, partitioned or segmented directories, it will not map the tables contained there. Even unexpected hidden files (e.g., those written by the Mac OS Finder) will abort the map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you point q startup at a directory, that directory becomes the root directory for the kdb+ database and also the current working directory for the OS. We shall refer to this scenario as kdb+ startup to distinguish it from an arbitrary q session. We shall cover the items that Kdb+ startup finds in the order that it handles them.\n",
    "\n",
    "1. Serialized q entities\n",
    "\n",
    "2. Splayed tables\n",
    "\n",
    "3. Partitioned or segmented tables\n",
    "\n",
    "4. Scripts\n",
    "\n",
    "File handles that are not fully qualified – i.e., relative paths – are interpreted relative to the q home directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serialized q Entities\n",
    "\n",
    "When kdb+ startup recognizes a serialized q data file, it loads that data into an eponymous variable. The canonical example is the sym file in the root, containing the serialized list of (unique) symbols in the enumeration domain for (all) symbol columns. Multiple serialized entities are loaded in the order in which the OS file system lists them.\n",
    "\n",
    "As of this writing (Sep 2015), q will not look for serialized data in directories other than the root. Nor will it automatically load serialized data whose file names have extensions. However, you can load such data files manually using `\\l` or `get`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splayed Tables\n",
    "\n",
    "When kdb+ startup finds a subdirectory immediately beneath the root that it recognizes as a splayed table, it maps the table into memory. All symbol columns must be enumerated for a table to be splayed. Ensure that the sym file is in the root directory if you do not use a built-in utility.\n",
    "\n",
    "\n",
    "#### Partitioned Tables\n",
    "\n",
    "If kdb+ startup finds subdirectories immediately beneath the root whose names constitute valid partition values, it examines them for splayed tables comprising partition slices. Valid partitioned tables are mapped. The presence of partitioned tables is independent of the presence of (plain) splayed tables. Partitioned tables and segmented tables are mutually exclusive.\n",
    "\n",
    "**All symbol columns in every partition slice must be enumerated, customarily over a file sym in the root. Ensure that the sym file is in the root directory if you do not use the built-in utilities.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmented Tables\n",
    "\n",
    "When kdb+ startup finds a `par.txt` file in the root, it interprets each line as a segment location and it examines the locations for valid segments of partitioned tables. Valid tables are mapped.\n",
    "\n",
    "**Ensure that the segment directories are not located under the root; otherwise you will relive the table scene in the first Alien movie.**\n",
    "\n",
    "#### Scripts\n",
    "\n",
    "Files with extension `.q` are interpreted as q scripts; those with extension `.k` as k scripts. Scripts found in the root are loaded and executed in alphabetical order. You will probably want better control over the order of execution, so it is best to have in the root a single script that loads other scripts in the desired sequence.\n",
    "\n",
    "**An invalid expression in a script causes the entire script load to abort. Locating the invalid entry can be non-trivial since by default console display is suppressed during load. Judicious use of 0N! can be helpful. Sometimes using binary search using block comments is an effective approach to locating the offending line. Bottom line: keep scripts short!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting It All Together\n",
    "### Partitioned Database\n",
    "### Segmented Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There's No Place Like `QHOME`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Environment Variables\n",
    "\n",
    "Three environment variables `QHOME`, `QLIC` and `QINIT` are used by kdb+ at startup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q in da hood\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T19:12:54.837075000Z",
     "start_time": "2020-11-30T19:12:54.833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1 \"cd ~ \",system \"cd\";}\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whereami:{-1 \"cd ~ \",system \"cd\";}\n",
    "whereami"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Q (kdb+)",
   "language": "q",
   "name": "qpk"
  },
  "language_info": {
   "file_extension": ".q",
   "mimetype": "text/x-q",
   "name": "q",
   "version": "4.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
